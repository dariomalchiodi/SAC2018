{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444 data items\n"
     ]
    }
   ],
   "source": [
    "# Data format:\n",
    "#\n",
    "# n0, n1, ...\n",
    "# mu0, k00, k01, ..., k0n\n",
    "# ...\n",
    "# mun, kn0, kn1, ..., knn\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "#data_file_name = 'data/axioms-toy.csv'\n",
    "#data_file_name = 'data/data-tettamanzi-little.csv'\n",
    "data_file_name = 'data/data-tettamanzi-complete.csv'\n",
    "\n",
    "with open(data_file_name) as data_file:\n",
    "    data = np.array(list(csv.reader(data_file)))\n",
    "\n",
    "n = len(data) - 1\n",
    "\n",
    "print '%d data items' % n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data names, membership values and Gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1444\n",
    "\n",
    "names = np.array(data[0])[1:n+1]\n",
    "mu = np.array([float(row[0]) for row in data[1:n+1]])\n",
    "gram = np.array([[float(k.replace('NA', '0')) for k in row[1:n+1]] for row in data[1:n+1]])\n",
    "\n",
    "assert(len(names.shape) == 1)\n",
    "assert(len(mu.shape) == 1)\n",
    "assert(len(gram.shape) == 2)\n",
    "assert(names.shape[0] == gram.shape[0] == gram.shape[1] == mu.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute adjustement in case of ill-conditioned Gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non PSD matrix: diagonal adjusment of 292.405301431\n"
     ]
    }
   ],
   "source": [
    "eigvals = np.linalg.eigvals(gram)\n",
    "assert(sum([abs(e.imag) for e in eigvals]) < 1e-4)\n",
    "abs_neg_eigvals = [-l.real for l in eigvals if l < 0]\n",
    "adjustment = max(abs_neg_eigvals) if abs_neg_eigvals else 0\n",
    "if adjustment:\n",
    "    print('non PSD matrix: diagonal adjusment of {0}'.format(adjustment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve hardness index for axioms ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1410 easy and 34 hard axioms\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('hardness.json', 'r') as f:\n",
    "    hardness = json.load(f)\n",
    "\n",
    "num_hard = sum(hardness)\n",
    "num_easy = n - num_hard\n",
    "hardness_count = (num_easy, num_hard)\n",
    "\n",
    "print 'There are {} easy and {} hard axioms'.format(num_easy, num_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Membership and possibility learning through repeated hold-out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from possibilearn import *\n",
    "from possibilearn.kernel import PrecomputedKernel\n",
    "from possibilearn.fuzzifiers import LinearFuzzifier\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "def estimate_possibility(n_all, mu_all, k, g, cs, ks, num_holdouts, percentages, fuzzifier,\n",
    "                         hardness_class,\n",
    "                         verbose=False):\n",
    "    assert(len(mu_all)==n_all)\n",
    "    axiom_indices = [i for i in range(n_all) if hardness[i]==hardness_class]\n",
    "    n = hardness_count[hardness_class]\n",
    "    mu = [mu_all[i] for i in range(len(mu_all)) if hardness[i]==hardness_class]\n",
    "    assert(len(axiom_indices)==len(mu)==n)\n",
    "\n",
    "    paired_axioms = [axiom_indices[i:i+2] for i in range(0, n, 2)]\n",
    "    paired_labels = [mu[i:i+2] for i in range(0, n, 2)]\n",
    "\n",
    "    metrics_membership_rmse = []\n",
    "    metrics_membership_median = []\n",
    "    metrics_membership_stdev = []\n",
    "\n",
    "    metrics_possibility_rmse = []\n",
    "    metrics_possibility_median = []\n",
    "    metrics_possibility_stdev = []\n",
    "\n",
    "    for h in range(num_holdouts):\n",
    "        (paired_values_train,\n",
    "         paired_values_validate,\n",
    "         paired_values_test,\n",
    "         paired_mu_train,\n",
    "         paired_mu_validate,\n",
    "         paired_mu_test) = split_indices(paired_axioms, paired_labels, percentages)\n",
    "\n",
    "        if verbose:\n",
    "            print 'holdout {} of {}'.format(h, num_holdouts)\n",
    "    \n",
    "        best_c, _, result = model_selection_holdout(paired_values_train, paired_mu_train,\n",
    "                                                    paired_values_validate, paired_mu_validate,\n",
    "                                                    cs, ks,\n",
    "                                                    sample_generator=g,\n",
    "                                                    log=True,\n",
    "                                                    adjustment=adjustment,\n",
    "                                                    fuzzifier=fuzzifier,\n",
    "                                                    verbose=verbose)\n",
    "        if best_c is None:\n",
    "            if verbose:\n",
    "                print 'in holdout {} optimization always failed!'.format(h)\n",
    "            continue\n",
    "    \n",
    "        if verbose:\n",
    "            print 'in holdout {} best C is {}'.format(h, best_c)\n",
    "        estimated_membership = result[0]\n",
    "    \n",
    "        # values and labels are still paired, we need to flatten them out\n",
    "        values_test = flatten(paired_values_test)\n",
    "        mu_test = flatten(paired_mu_test)\n",
    "\n",
    "        membership_square_err = [(estimated_membership(v) - m)**2 for v, m in zip(values_test, mu_test)]\n",
    "        membership_rmse = math.sqrt(sum(membership_square_err) / len(values_test))\n",
    "        metrics_membership_rmse.append(membership_rmse)\n",
    "    \n",
    "        membership_median = np.median(membership_square_err)\n",
    "        metrics_membership_median.append(membership_median)\n",
    "    \n",
    "        membership_stdev = np.std(membership_square_err)\n",
    "        metrics_membership_stdev.append(membership_stdev)\n",
    "    \n",
    "        estimated_mu = map(estimated_membership, values_test)\n",
    "        actual_possibility = [mfi - mnotfi for mfi, mnotfi in zip(mu_test[::2], mu_test[1::2])]\n",
    "        estimated_possibility = [mfi - mnotfi\n",
    "                                 for mfi, mnotfi in zip(estimated_mu[::2], estimated_mu[1::2])]\n",
    "    \n",
    "        possibility_square_err = [(actual - estimated)**2\n",
    "                              for actual, estimated in zip(actual_possibility, estimated_possibility)]\n",
    "        possibility_rmse = math.sqrt(sum(possibility_square_err) / len(possibility_square_err))\n",
    "        metrics_possibility_rmse.append(possibility_rmse)\n",
    "    \n",
    "        possibility_median = np.median(possibility_square_err)\n",
    "        metrics_possibility_median.append(possibility_median)\n",
    "    \n",
    "        possibility_stdev = np.std(possibility_square_err)\n",
    "        metrics_possibility_stdev.append(possibility_stdev)\n",
    "    \n",
    "        indices = ['-'.join(map(str, pair)) for pair in paired_values_test]\n",
    "\n",
    "        results = [(i, phi, notphi, max(phi, notphi), ephi, enotphi, max(ephi, enotphi), p, ep, (p - ep)**2)\n",
    "                   for i, phi, notphi, p, ephi, enotphi, ep in zip(indices, mu_test[::2], mu_test[1::2], actual_possibility,\n",
    "                                                            estimated_mu[::2], estimated_mu[1::2], estimated_possibility)]\n",
    "\n",
    "        results.sort(key = lambda r: r[-1])        \n",
    "        errors = [r[-1] for r in results]\n",
    "\n",
    "    if verbose:\n",
    "        print 'Membership average values:'\n",
    "        print 'RMSE: {}'.format(np.average(metrics_membership_rmse))\n",
    "        print 'Median: {}'.format(np.average(metrics_membership_median))\n",
    "        print 'STDEV: {}'.format(np.average(metrics_membership_stdev))\n",
    "\n",
    "        print 'Possibility average values:'\n",
    "        print 'RMSE: {}'.format(np.average(metrics_possibility_rmse))\n",
    "        print 'Median: {}'.format(np.average(metrics_possibility_median))\n",
    "        print 'STDEV: {}'.format(np.average(metrics_possibility_stdev))\n",
    "    \n",
    "    return (np.average(metrics_membership_rmse),\n",
    "            np.average(metrics_membership_median),\n",
    "            np.average(metrics_membership_stdev),\n",
    "            np.average(metrics_possibility_rmse),\n",
    "            np.average(metrics_possibility_median),\n",
    "            np.average(metrics_possibility_stdev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from possibilearn.fuzzifiers import *\n",
    "\n",
    "hardness_class = 1\n",
    "\n",
    "k = PrecomputedKernel(gram)\n",
    "axiom_indices = axiom_indices = [i for i in range(n) if hardness[i]==hardness_class]\n",
    "\n",
    "def g(m):\n",
    "    return np.random.choice(axiom_indices, m if m <= len(axiom_indices) else len(axiom_indices))\n",
    "\n",
    "cs = (0.07, 0.1, 0.3, 0.5, 0.7, 1, 10, 100)\n",
    "cs = np.arange(0.05, 1, 0.01)\n",
    "ks = (k,)\n",
    "\n",
    "num_holdouts = 10\n",
    "percentages = (.8, .1, .1)\n",
    "\n",
    "fuzzifiers = [CrispFuzzifier(), LinearFuzzifier(), QuantileConstantPiecewiseFuzzifier(),\n",
    "              QuantileLinearPiecewiseFuzzifier()] + [ExponentialFuzzifier(gamma) \n",
    "                                                     for gamma in np.arange(0.1, 1, 0.1)] + \\\n",
    "              [ExponentialFuzzifier(gamma) for gamma in np.arange(0.91, 1, 0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = [estimate_possibility(n, mu, k, g,\n",
    "                               cs, ks, num_holdouts,\n",
    "                               percentages, f,\n",
    "                               hardness_class,\n",
    "                               verbose=False) for f in fuzzifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\mu$ RMSE</th>\n",
       "      <th>$\\mu$ median</th>\n",
       "      <th>$\\mu$ STD</th>\n",
       "      <th>$\\pi$ RMSE</th>\n",
       "      <th>$\\pi$ median</th>\n",
       "      <th>$\\pi$ STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Crisp</th>\n",
       "      <td>0.916387</td>\n",
       "      <td>0.936732</td>\n",
       "      <td>0.217403</td>\n",
       "      <td>1.804482</td>\n",
       "      <td>3.432454</td>\n",
       "      <td>0.659469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.783529</td>\n",
       "      <td>0.697548</td>\n",
       "      <td>0.378821</td>\n",
       "      <td>1.470733</td>\n",
       "      <td>1.991265</td>\n",
       "      <td>1.066544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileConstPiecewise</th>\n",
       "      <td>0.781112</td>\n",
       "      <td>0.655617</td>\n",
       "      <td>0.309724</td>\n",
       "      <td>1.505775</td>\n",
       "      <td>2.493840</td>\n",
       "      <td>0.824312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileLinPiecewise</th>\n",
       "      <td>0.759446</td>\n",
       "      <td>0.651334</td>\n",
       "      <td>0.377025</td>\n",
       "      <td>1.441806</td>\n",
       "      <td>2.029638</td>\n",
       "      <td>1.116787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.1)</th>\n",
       "      <td>0.900859</td>\n",
       "      <td>0.915939</td>\n",
       "      <td>0.212241</td>\n",
       "      <td>1.771254</td>\n",
       "      <td>3.159936</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.2)</th>\n",
       "      <td>0.849560</td>\n",
       "      <td>0.813026</td>\n",
       "      <td>0.295438</td>\n",
       "      <td>1.654272</td>\n",
       "      <td>3.069841</td>\n",
       "      <td>0.856402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.3)</th>\n",
       "      <td>0.840431</td>\n",
       "      <td>0.776097</td>\n",
       "      <td>0.291393</td>\n",
       "      <td>1.636222</td>\n",
       "      <td>3.023952</td>\n",
       "      <td>0.848018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.4)</th>\n",
       "      <td>0.750790</td>\n",
       "      <td>0.554311</td>\n",
       "      <td>0.291441</td>\n",
       "      <td>1.447816</td>\n",
       "      <td>2.160981</td>\n",
       "      <td>0.704323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.5)</th>\n",
       "      <td>0.679367</td>\n",
       "      <td>0.417354</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>1.223093</td>\n",
       "      <td>1.480594</td>\n",
       "      <td>0.488154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.6)</th>\n",
       "      <td>0.668848</td>\n",
       "      <td>0.387990</td>\n",
       "      <td>0.363874</td>\n",
       "      <td>1.210975</td>\n",
       "      <td>1.552695</td>\n",
       "      <td>0.578769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.7)</th>\n",
       "      <td>0.657053</td>\n",
       "      <td>0.345917</td>\n",
       "      <td>0.405080</td>\n",
       "      <td>1.113488</td>\n",
       "      <td>1.284656</td>\n",
       "      <td>0.438039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.8)</th>\n",
       "      <td>0.624712</td>\n",
       "      <td>0.277951</td>\n",
       "      <td>0.416220</td>\n",
       "      <td>0.992545</td>\n",
       "      <td>0.992578</td>\n",
       "      <td>0.324370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.9)</th>\n",
       "      <td>0.634245</td>\n",
       "      <td>0.243337</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>1.028248</td>\n",
       "      <td>0.251228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.91)</th>\n",
       "      <td>0.606967</td>\n",
       "      <td>0.180429</td>\n",
       "      <td>0.427214</td>\n",
       "      <td>0.897595</td>\n",
       "      <td>0.926256</td>\n",
       "      <td>0.308027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.92)</th>\n",
       "      <td>0.585150</td>\n",
       "      <td>0.183539</td>\n",
       "      <td>0.394190</td>\n",
       "      <td>0.876698</td>\n",
       "      <td>0.910788</td>\n",
       "      <td>0.283628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.93)</th>\n",
       "      <td>0.651844</td>\n",
       "      <td>0.299862</td>\n",
       "      <td>0.456158</td>\n",
       "      <td>0.959103</td>\n",
       "      <td>1.036852</td>\n",
       "      <td>0.200446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.94)</th>\n",
       "      <td>0.651719</td>\n",
       "      <td>0.338139</td>\n",
       "      <td>0.458013</td>\n",
       "      <td>0.951850</td>\n",
       "      <td>0.954744</td>\n",
       "      <td>0.165176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.95)</th>\n",
       "      <td>0.628553</td>\n",
       "      <td>0.261316</td>\n",
       "      <td>0.438203</td>\n",
       "      <td>0.913112</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.215551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.96)</th>\n",
       "      <td>0.643763</td>\n",
       "      <td>0.298903</td>\n",
       "      <td>0.451689</td>\n",
       "      <td>0.925387</td>\n",
       "      <td>0.942475</td>\n",
       "      <td>0.185966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.97)</th>\n",
       "      <td>0.655318</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>0.463830</td>\n",
       "      <td>0.941516</td>\n",
       "      <td>0.924564</td>\n",
       "      <td>0.130991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.98)</th>\n",
       "      <td>0.622739</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>0.438976</td>\n",
       "      <td>0.890845</td>\n",
       "      <td>0.933944</td>\n",
       "      <td>0.241854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential(0.99)</th>\n",
       "      <td>0.616710</td>\n",
       "      <td>0.229274</td>\n",
       "      <td>0.428298</td>\n",
       "      <td>0.877685</td>\n",
       "      <td>0.891229</td>\n",
       "      <td>0.233194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        $\\mu$ RMSE  $\\mu$ median  $\\mu$ STD  $\\pi$ RMSE  \\\n",
       "Crisp                     0.916387      0.936732   0.217403    1.804482   \n",
       "Linear                    0.783529      0.697548   0.378821    1.470733   \n",
       "QuantileConstPiecewise    0.781112      0.655617   0.309724    1.505775   \n",
       "QuantileLinPiecewise      0.759446      0.651334   0.377025    1.441806   \n",
       "Exponential(0.1)          0.900859      0.915939   0.212241    1.771254   \n",
       "Exponential(0.2)          0.849560      0.813026   0.295438    1.654272   \n",
       "Exponential(0.3)          0.840431      0.776097   0.291393    1.636222   \n",
       "Exponential(0.4)          0.750790      0.554311   0.291441    1.447816   \n",
       "Exponential(0.5)          0.679367      0.417354   0.356223    1.223093   \n",
       "Exponential(0.6)          0.668848      0.387990   0.363874    1.210975   \n",
       "Exponential(0.7)          0.657053      0.345917   0.405080    1.113488   \n",
       "Exponential(0.8)          0.624712      0.277951   0.416220    0.992545   \n",
       "Exponential(0.9)          0.634245      0.243337   0.446809    0.946584   \n",
       "Exponential(0.91)         0.606967      0.180429   0.427214    0.897595   \n",
       "Exponential(0.92)         0.585150      0.183539   0.394190    0.876698   \n",
       "Exponential(0.93)         0.651844      0.299862   0.456158    0.959103   \n",
       "Exponential(0.94)         0.651719      0.338139   0.458013    0.951850   \n",
       "Exponential(0.95)         0.628553      0.261316   0.438203    0.913112   \n",
       "Exponential(0.96)         0.643763      0.298903   0.451689    0.925387   \n",
       "Exponential(0.97)         0.655318      0.356307   0.463830    0.941516   \n",
       "Exponential(0.98)         0.622739      0.229041   0.438976    0.890845   \n",
       "Exponential(0.99)         0.616710      0.229274   0.428298    0.877685   \n",
       "\n",
       "                        $\\pi$ median  $\\pi$ STD  \n",
       "Crisp                       3.432454   0.659469  \n",
       "Linear                      1.991265   1.066544  \n",
       "QuantileConstPiecewise      2.493840   0.824312  \n",
       "QuantileLinPiecewise        2.029638   1.116787  \n",
       "Exponential(0.1)            3.159936   0.525210  \n",
       "Exponential(0.2)            3.069841   0.856402  \n",
       "Exponential(0.3)            3.023952   0.848018  \n",
       "Exponential(0.4)            2.160981   0.704323  \n",
       "Exponential(0.5)            1.480594   0.488154  \n",
       "Exponential(0.6)            1.552695   0.578769  \n",
       "Exponential(0.7)            1.284656   0.438039  \n",
       "Exponential(0.8)            0.992578   0.324370  \n",
       "Exponential(0.9)            1.028248   0.251228  \n",
       "Exponential(0.91)           0.926256   0.308027  \n",
       "Exponential(0.92)           0.910788   0.283628  \n",
       "Exponential(0.93)           1.036852   0.200446  \n",
       "Exponential(0.94)           0.954744   0.165176  \n",
       "Exponential(0.95)           0.918854   0.215551  \n",
       "Exponential(0.96)           0.942475   0.185966  \n",
       "Exponential(0.97)           0.924564   0.130991  \n",
       "Exponential(0.98)           0.933944   0.241854  \n",
       "Exponential(0.99)           0.891229   0.233194  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(result, columns=('$\\mu$ RMSE', '$\\mu$ median', '$\\mu$ STD',\n",
    "                              '$\\pi$ RMSE', '$\\pi$ median', '$\\pi$ STD'),\n",
    "            index=[f.name for f in fuzzifiers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "easy_axioms, hard_axioms split(axioms)\n",
    "\n",
    "easy_axioms_train, easy_axioms_test = split(easy_axioms)\n",
    "hard_axioms_train, hard_axioms_test = split(hard_axioms)\n",
    "\n",
    "learn_easy_classifier(easy_axioms_train)\n",
    "learn_hard_classifier(hard_axioms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from possibilearn import split_indices, flatten\n",
    "\n",
    "def learn_two_stage_classifier(n, mu, hardness,\n",
    "                               easy_c, hard_c,\n",
    "                               easy_sample_generator, hard_sample_generator,\n",
    "                               easy_fuzzifier, hard_fuzzifier):\n",
    "    assert(len(mu)==n)\n",
    "    hard_axiom_indices = [i for i in range(n) if hardness[i]]\n",
    "    num_hard_axioms = len(hard_axiom_indices)\n",
    "    mu_hard_axioms = [mu[i] for i in range(n) if hardness[i]]\n",
    "    \n",
    "    easy_axiom_indices = [i for i in range(n) if not hardness[i]]\n",
    "    num_easy_axioms = len(easy_axiom_indices)\n",
    "    mu_easy_axioms = [mu[i] for i in range(n) if not hardness[i]]\n",
    "    \n",
    "    assert(num_easy_axioms + num_hard_axioms == n)\n",
    "\n",
    "    paired_hard_axioms = [hard_axiom_indices[i:i+2] for i in range(0, num_hard_axioms, 2)]\n",
    "    paired_hard_labels = [mu_hard_axioms[i:i+2] for i in range(0, num_hard_axioms, 2)]\n",
    "    \n",
    "    paired_easy_axioms = [easy_axiom_indices[i:i+2] for i in range(0, num_easy_axioms, 2)]\n",
    "    paired_easy_labels = [mu_easy_axioms[i:i+2] for i in range(0, num_easy_axioms, 2)]\n",
    "    \n",
    "    percentages = (.9, 0, .1)\n",
    "\n",
    "    (paired_easy_axioms_train,\n",
    "     _,\n",
    "     paired_easy_axioms_test,\n",
    "     paired_easy_mu_train,\n",
    "     _,\n",
    "     paired_easy_mu_test) = split_indices(paired_easy_axioms, paired_easy_labels, percentages)\n",
    "    \n",
    "    (paired_hard_axioms_train,\n",
    "     _,\n",
    "     paired_hard_axioms_test,\n",
    "     paired_hard_mu_train,\n",
    "     _,\n",
    "     paired_hard_mu_test) = split_indices(paired_hard_axioms, paired_hard_labels, percentages)\n",
    "    \n",
    "    easy_axioms_train = flatten(paired_easy_axioms_train)\n",
    "    easy_axioms_test = flatten(paired_easy_axioms_test)\n",
    "    easy_mu_train = flatten(paired_easy_mu_train)\n",
    "    easy_mu_test = flatten(paired_easy_mu_test)\n",
    "    \n",
    "    hard_axioms_train = flatten(paired_hard_axioms_train)\n",
    "    hard_axioms_test = flatten(paired_hard_axioms_test)\n",
    "    hard_mu_train = flatten(paired_hard_mu_train)\n",
    "    hard_mu_test = flatten(paired_hard_mu_test)\n",
    "    \n",
    "    easy_result = possibility_learn(easy_axioms_train, easy_mu_train, easy_c, k,\n",
    "                                          sample_generator=easy_sample_generator,\n",
    "                                          adjustment=adjustment,\n",
    "                                          fuzzifier=easy_fuzzifier,\n",
    "                                          crisp=False)\n",
    "    hard_result = possibility_learn(hard_axioms_train, hard_mu_train, hard_c, k,\n",
    "                                          sample_generator=hard_sample_generator,\n",
    "                                          adjustment=adjustment,\n",
    "                                          fuzzifier=hard_fuzzifier,\n",
    "                                          crisp=False)\n",
    "    return (easy_result, hard_result,\n",
    "            easy_axioms_test, easy_mu_test, hard_axioms_test, hard_mu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "easy_c = 0.1\n",
    "hard_c = 0.92\n",
    "\n",
    "hard_axiom_indices = [i for i in range(n) if hardness[i]]\n",
    "easy_axiom_indices = [i for i in range(n) if not hardness[i]]\n",
    "\n",
    "def easy_sample_generator(m):\n",
    "    return np.random.choice(easy_axiom_indices, m if m <= len(easy_axiom_indices) \\\n",
    "                            else len(easy_axiom_indices))\n",
    "\n",
    "def hard_sample_generator(m):\n",
    "    return np.random.choice(hard_axiom_indices, m if m <= len(hard_axiom_indices) \\\n",
    "                            else len(hard_axiom_indices))\n",
    "\n",
    "def collect_pairs(l):\n",
    "    return [l[i:i+2] for i in range(0, len(l), 2)]\n",
    "\n",
    "def two_stage_experiment():\n",
    "    easy_fuzzifier = CrispFuzzifier()\n",
    "    hard_fuzzifier = ExponentialFuzzifier(0.92)\n",
    "\n",
    "    easy_result, hard_result, \\\n",
    "    easy_axioms_test, easy_mu_test, \\\n",
    "    hard_axioms_test, hard_mu_test = learn_two_stage_classifier(n, mu, hardness,\n",
    "                                                            easy_c, hard_c,\n",
    "                                                            easy_sample_generator,\n",
    "                                                            hard_sample_generator,\n",
    "                                                            easy_fuzzifier, hard_fuzzifier)\n",
    "    easy_membership = easy_result[0]\n",
    "    hard_membership = hard_result[0]\n",
    "    \n",
    "    paired_easy_axioms_test = collect_pairs(easy_axioms_test)\n",
    "    paired_easy_mu_test = collect_pairs(easy_mu_test)\n",
    "\n",
    "    paired_hard_axioms_test = collect_pairs(hard_axioms_test)\n",
    "    paired_hard_mu_test = collect_pairs(hard_mu_test)\n",
    "\n",
    "    paired_axioms_test = paired_easy_axioms_test + paired_hard_axioms_test\n",
    "    paired_mu_test = paired_easy_mu_test + paired_hard_mu_test\n",
    "    \n",
    "    def two_stage_classifier(axiom_pair):\n",
    "        mus = map(easy_membership, axiom_pair)\n",
    "        p = mus[0] - mus[1]\n",
    "        if np.abs(p) < 0.7:\n",
    "            mus = map(hard_membership, axiom_pair)\n",
    "            p = mus[0] - mus[1]\n",
    "        return p\n",
    "    \n",
    "    def get_performance(actual, estimated):\n",
    "        actual_p = [mus[0] - mus[1] for mus in actual]\n",
    "        estimated_p = map(two_stage_classifier, estimated)\n",
    "        result = map(lambda p: (p[0]-p[1])**2, zip(actual_p, estimated_p))\n",
    "        return (np.mean(result), np.median(result))\n",
    "    \n",
    "    return (get_performance(paired_mu_test, paired_axioms_test),\n",
    "            get_performance(paired_easy_mu_test, paired_easy_axioms_test),\n",
    "            get_performance(paired_hard_mu_test, paired_hard_axioms_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result = [two_stage_experiment() for _ in range(10)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(map(flatten, final_result),\n",
    "             columns=('mean, all', 'median, all',\n",
    "                      'mean, easy', 'median, easy',\n",
    "                      'mean, hard', 'median, hard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean, all       0.370555\n",
       "median, all     0.000957\n",
       "mean, easy      0.276649\n",
       "median, easy    0.000897\n",
       "mean, hard      3.704236\n",
       "median, hard    3.704236\n",
       "dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
